{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data With VINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generated the data and ICE curves in R and adjusted some functions from the original Repo (https://github.com/MattJBritton/VINE) to make results comparable with REPID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#scikit-learn\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import datasets\n",
    "#from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "\n",
    "\n",
    "#matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from original PyCEBox library\n",
    "#get the x_values for a given granularity of curve\n",
    "def _get_grid_points(x, num_grid_points):\n",
    "    if sorted(list(x.unique())) == [0,1]:\n",
    "        return [0.,1.], \"categorical\"\n",
    "    if num_grid_points is None:\n",
    "        return x.unique(), \"numeric\"\n",
    "    else:\n",
    "        # unique is necessary, because if num_grid_points is too much larger\n",
    "        # than x.shape[0], there will be duplicate quantiles (even with\n",
    "        # interpolation)\n",
    "        return x.quantile(np.linspace(0, 1, num_grid_points)).unique(), \"numeric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from original PyCEBox library\n",
    "#average the PDP lines (naive method seems to work fine)\n",
    "def _pdp(ice_data):\n",
    "    return ice_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform curves before distance measurement\n",
    "def _differentiate(series):\n",
    "        \n",
    "    dS = np.diff(series)\n",
    "    return dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for testing random clusters to ensure that algorithm performance is superior\n",
    "def _test_random_clusters(ice_data, num_clusters=5):\n",
    "    temp = np.random.uniform(size=num_clusters)\n",
    "    distribution = temp/temp.sum()\n",
    "    cluster_labels = np.random.choice(a = range(num_clusters),\\\n",
    "                                      size=ice_data.shape[0],\\\n",
    "                                      replace=True, p=distribution)\n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolate lines to num_grid_points when comparing features for feature-space statistics\n",
    "def _interpolate_line(x, y, length):\n",
    "    if len(y) == length:\n",
    "        return y\n",
    "    else:\n",
    "        f = interp1d(x,y, kind=\"cubic\")\n",
    "        return list(f(np.linspace(x[0], x[-1], num=length, endpoint=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate VINE clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_model_split(columns, model):\n",
    "    split_feature = columns[model.tree_.feature[0]] if model.tree_.value.shape[0] > 1 else 'none'\n",
    "    split_val = round(model.tree_.threshold[0],2)\n",
    "    split_direction = \"<=\" if model.tree_.value.shape[0] == 1\\\n",
    "    or model.classes_[np.argmax(model.tree_.value[1])] == 1 else \">\"\n",
    "    return split_feature, split_val, split_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_adj2(ice_data, data, x_s, column_of_interest, ice_name, num_clusters=5, num_grid_points=20,\\\n",
    "           ice_curves_to_export=100, cluster_method=\"vine\"):\n",
    "    \n",
    "    ice_data.columns = x_s\n",
    "    export_dict = {\"features\":{}, \"distributions\":{}}\n",
    "    ice_data = ice_data.sub(ice_data.mean(axis=1), axis='index')\n",
    "    pdp_data = _pdp(ice_data)\n",
    "    export_dict[\"features\"][column_of_interest] = {\"feature_name\": column_of_interest,\n",
    "                                                       \"x_values\": list(x_s),\n",
    "                                                       \"pdp_line\": list(pdp_data),\n",
    "                                                       \"clusters\":[]\n",
    "                                                      }\n",
    "        \n",
    "    export_dict[\"features\"][column_of_interest][\"ice_data\"] = np.array(ice_data) \n",
    "\n",
    "    #perform clustering\n",
    "    if cluster_method == \"vine\":\n",
    "        ice_data[\"cluster_label\"] = AgglomerativeClustering(n_clusters = num_clusters)\\\n",
    "                .fit(_differentiate(ice_data.values)).labels_\n",
    "    elif cluster_method == \"random\":\n",
    "        ice_data[\"cluster_label\"] = _test_random_clusters(ice_data, num_clusters)\n",
    "            \n",
    "    #print(ice_data[x_s].values)      \n",
    "    ice_data[\"points\"] = ice_data[x_s].values.tolist() \n",
    "\n",
    "    #generate all the ICE curves per cluster\n",
    "    all_curves_by_cluster = ice_data.groupby(\"cluster_label\")[\"points\"].apply(lambda x: np.array(x)) \n",
    "        \n",
    "    splits_first_pass = []\n",
    "    for cluster_num in range(len(all_curves_by_cluster)):                          \n",
    "        num_curves_in_cluster = len(all_curves_by_cluster[cluster_num])\n",
    "\n",
    "        #build model to predict cluster membership\n",
    "        rdwcY = ice_data[\"cluster_label\"].apply(lambda x: 1 if x==cluster_num else 0)\n",
    "        #1-node decision tree to get best split for each cluster\n",
    "        model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=1, presort=False,\\\n",
    "                                           class_weight=\"balanced\")\n",
    "        model.fit(data, rdwcY)\n",
    "        split_feature, split_val, split_direction = _get_model_split(data.columns, model)\n",
    "        splits_first_pass.append({\"feature\":split_feature, \"val\":split_val,\\\n",
    "                                      \"direction\": split_direction, \"model\": model})\n",
    "       \n",
    "    #loop through splits to find duplicates\n",
    "    duplicate_splits = {}\n",
    "    for i, split_def in enumerate(splits_first_pass[:-1]):\n",
    "        for j, split_def_2 in enumerate(splits_first_pass):\n",
    "            if j<=i or i in duplicate_splits or j in duplicate_splits:\n",
    "                continue\n",
    "            elif split_def[\"feature\"] == split_def_2[\"feature\"]\\\n",
    "            and split_def[\"direction\"] == split_def_2[\"direction\"]\\\n",
    "            and (split_def[\"val\"] - split_def_2[\"val\"])/(np.ptp(data.loc[:,split_def[\"feature\"]])) <= 0.1:\n",
    "                duplicate_splits[j] = i\n",
    "\n",
    "    ice_data = ice_data.replace(to_replace={\"cluster_label\":duplicate_splits}, value=None)\n",
    "    # save ice data to visualize in R\n",
    "    ice_data.to_csv(ice_name)\n",
    "\n",
    "    #generate all the ICE curves per cluster\n",
    "    all_curves_by_cluster = ice_data.groupby(\"cluster_label\")[\"points\"].apply(lambda x: np.array(x)) \n",
    "    #average the above to get the mean cluster line\n",
    "    cluster_average_curves = {key:np.mean(np.array(list(value)), axis=0)\\\n",
    "                            for key,value in all_curves_by_cluster.iteritems()}\n",
    "        \n",
    "    for cluster_num in all_curves_by_cluster.keys():                          \n",
    "        num_curves_in_cluster = len(all_curves_by_cluster[cluster_num])\n",
    "\n",
    "        #build model to predict cluster membership\n",
    "        rdwcY = ice_data[\"cluster_label\"].apply(lambda x: 1 if x==cluster_num else 0)\n",
    "        model = splits_first_pass[cluster_num][\"model\"]\n",
    "        predY = model.predict(data) \n",
    "        split_feature, split_val, split_direction = _get_model_split(data.columns, model)   \n",
    "\n",
    "        #get random curves if there are more than 100\n",
    "    \n",
    "    #no reason to make the visualization display 1000+ ICE curves for this tool\n",
    "        if num_curves_in_cluster > ice_curves_to_export:\n",
    "            individual_ice_samples = [list(x) for x in\\\n",
    "                                        list(all_curves_by_cluster[cluster_num]\\\n",
    "                                        [np.random.choice(num_curves_in_cluster,\\\n",
    "                                                size=ice_curves_to_export, replace=False)])\n",
    "                                        ]\n",
    "        else:\n",
    "            individual_ice_samples = [list(x) for x in\\\n",
    "                                        list(all_curves_by_cluster[cluster_num])\\\n",
    "                                        ]\n",
    "        \n",
    "        #add cluster-level metrics to the output dict\n",
    "        export_dict[\"features\"][column_of_interest][\"clusters\"].append({\n",
    "                'accuracy': int(round(100.*metrics.accuracy_score(rdwcY, predY))),\n",
    "                'precision': int(round(100.*metrics.precision_score(rdwcY, predY))),\n",
    "                'recall': int(round(100.*metrics.recall_score(rdwcY, predY))),\n",
    "                'split_feature': split_feature,\n",
    "                'split_val': split_val,\n",
    "                'split_direction': split_direction,                   \n",
    "                'predict_function': model.predict, \n",
    "                'cluster_size': num_curves_in_cluster,\n",
    "                'line': list(cluster_average_curves[cluster_num])\n",
    "        })  \n",
    "    return(export_dict)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data and export for analysis in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: create ice curves in R (to be more comparable) and export them again with class labels created by vine\n",
    "X = pd.read_csv(\"../data/sim_vine_vs_repid/data.csv\", sep=\",\", decimal=\".\")\n",
    "\n",
    "\n",
    "# grid data copied\n",
    "x_s = np.array([-0.99931637, -0.89416256, -0.78900875, -0.68385494, -0.57870113, -0.47354732, -0.36839350, -0.26323969, -0.15808588, -0.05293207,\n",
    "  0.05222174,  0.15737556,  0.26252937,  0.36768318,  0.47283699,  0.57799080,  0.68314462,  0.78829843,  0.89345224,  0.99860605])\n",
    "\n",
    "# read in ice data created in R\n",
    "ice_data = pd.read_csv(\"../data/sim_vine_vs_repid/ice_data_Sim1.csv\", sep=\";\", decimal=\",\", index_col=0)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 clusters\n",
    "VINE_data = export_adj2(ice_data = ice_data, data = X, x_s = x_s, column_of_interest = \"x2\", ice_name = \"../data/sim_vine_vs_repid/test.csv\", num_clusters=5, num_grid_points=20,\\\n",
    "           ice_curves_to_export=500, cluster_method=\"vine\")\n",
    "VINE_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 clusters\n",
    "VINE_data = export_adj2(ice_data = ice_data, data = X, x_s = x_s, column_of_interest = \"x2\", ice_name = \"../data/result2Clusters.csv\", num_clusters=2, num_grid_points=20,\\\n",
    "           ice_curves_to_export=500, cluster_method=\"vine\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
